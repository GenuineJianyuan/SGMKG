{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Canonicalization for io-data and functional step (the implementation for these two are the same)\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "model_name = 'BAAI/bge-m3'\n",
    "# pth_file = r'canon\\step_entity_preprocessing.pth'\n",
    "# input_csv_path = r'canon\\functional_step_entities_with_content.csv'\n",
    "pth_file = r'canon\\data_entity_preprocessing.pth'\n",
    "input_csv_path = r'canon\\io_data_entities_with_content.csv'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "def load_embeddings():\n",
    "    if os.path.exists(pth_file):\n",
    "        return torch.load(pth_file, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def get_similarity(embedding1, embedding2):\n",
    "    sim = torch.cosine_similarity(embedding1, embedding2, dim=1)\n",
    "    return sim.item()\n",
    "\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "is_visited = []\n",
    "ids = []\n",
    "for index , row in df.iterrows():\n",
    "    cur_id = row['id']\n",
    "    ids.append(cur_id)\n",
    "    is_visited.append(False)\n",
    "\n",
    "count = len(is_visited)\n",
    "embeddings = load_embeddings()\n",
    "\n",
    "canon_dict = {}\n",
    "\n",
    "start_time = time.time()\n",
    "for i, id in enumerate(ids):\n",
    "    if is_visited[i]:\n",
    "        print(f\"{i}:{id} has been clustered, {count} left\")\n",
    "        count = count -1\n",
    "        continue\n",
    "    count = count -1\n",
    "    print(f\"Processing {i}:{id}, {count} left\")\n",
    "    ## For unused embeddings, create a standardized set and compute similarities for the remaining items to find those similar to the current ID.\n",
    "    if id not in canon_dict:\n",
    "        canon_dict[id] = []\n",
    "    embedding1 = embeddings[id]\n",
    "    for j in range(i+1, len(ids)):\n",
    "        if is_visited[j]:\n",
    "            continue\n",
    "        cur_id = ids[j]\n",
    "        embedding2 = embeddings[cur_id]\n",
    "        similarity = get_similarity(embedding1, embedding2)\n",
    "        if similarity>=0.76:\n",
    "            is_visited[j] = True\n",
    "            canon_dict[id].append(cur_id)\n",
    "    is_visited[i] = True\n",
    "    end_time = time.time()\n",
    "    print(f\"Total processing time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "folder_path = r\"canon\"\n",
    "# file_path = os.path.join(folder_path, 'functional_step.json')\n",
    "file_path = os.path.join(folder_path, 'io_data.json')\n",
    "\n",
    "with open(file_path, 'w', encoding='utf-8-sig') as json_file:\n",
    "    json.dump(canon_dict, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Finish, total processing time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save kg_canonicalization to db to create entities and relations\n",
    "\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "# Step 1: Read two JSON files and merge their keys and values into a set\n",
    "def load_json_to_set(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
    "        data = json.load(file)\n",
    "    return {k: {k}.union(set(v)) for k, v in data.items()}\n",
    "\n",
    "# Read io_data.json file\n",
    "io_data_file_path = r\"your/custom/path/io_data.json\"\n",
    "key_value_set = load_json_to_set(io_data_file_path)\n",
    "\n",
    "# Read functional_step.json file and merge it into key_value_set\n",
    "functional_step_file_path = r\"your/custom/path/functional_step.json\"\n",
    "functional_step_set = load_json_to_set(functional_step_file_path)\n",
    "\n",
    "# Merge the two sets\n",
    "for k, v in functional_step_set.items():\n",
    "    if k in key_value_set:\n",
    "        key_value_set[k].update(v)\n",
    "    else:\n",
    "        key_value_set[k] = v\n",
    "\n",
    "# Step 2: Connect to SQLite database and read raw_entity table\n",
    "db_path = r\"your/custom/path/sgmkg.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create a new table and copy data\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS canon_entity (\n",
    "        id TEXT PRIMARY KEY,\n",
    "        entity_type TEXT,\n",
    "        short_name TEXT,\n",
    "        descr TEXT,\n",
    "        new_id TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Copy data to the new table and update the new_id field based on key_value_set\n",
    "cursor.execute('SELECT id, entity_type, short_name, descr FROM raw_entity')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "for row in rows:\n",
    "    entity_id, entity_type, short_name, descr = row\n",
    "    new_id = None\n",
    "    \n",
    "    # Find the matching key_value_set\n",
    "    for key, value_set in key_value_set.items():\n",
    "        if entity_id in value_set:\n",
    "            new_id = key\n",
    "            break\n",
    "    \n",
    "    cursor.execute('''\n",
    "        INSERT OR REPLACE INTO canon_entity (id, entity_type, short_name, descr, new_id)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "    ''', (entity_id, entity_type, short_name, descr, new_id))\n",
    "\n",
    "# Commit changes and close the database connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data has been successfully copied and updated into the canon_entity table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to SQLite database\n",
    "db_path = r\"your/custom/path/sgmkg.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create a new table canon_relation_init with the same fields as raw_relation\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS canon_relation_init (\n",
    "        id TEXT PRIMARY KEY,\n",
    "        output_entity_id TEXT,\n",
    "        input_entity_id TEXT,\n",
    "        relation_type TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Read data from the raw_relation table\n",
    "cursor.execute('SELECT id, output_entity_id, input_entity_id, relation_type FROM raw_relation')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Update output_entity_id and input_entity_id using new_id from canon_entity table\n",
    "for row in rows:\n",
    "    relation_id, output_entity_id, input_entity_id, relation_type = row\n",
    "    \n",
    "    # Get the new value for output_entity_id\n",
    "    cursor.execute('SELECT new_id FROM canon_entity WHERE id = ?', (output_entity_id,))\n",
    "    output_new_id = cursor.fetchone()\n",
    "    if output_new_id and (relation_type == 'invoke' or relation_type == 'transfer'):\n",
    "        output_entity_id = output_new_id[0]\n",
    "    \n",
    "    # Get the new value for input_entity_id\n",
    "    cursor.execute('SELECT new_id FROM canon_entity WHERE id = ?', (input_entity_id,))\n",
    "    input_new_id = cursor.fetchone()\n",
    "    if input_new_id and (relation_type == 'invoke' or relation_type == 'transfer'):\n",
    "        input_entity_id = input_new_id[0]\n",
    "    \n",
    "    # Insert the updated data into the canon_relation_init table\n",
    "    cursor.execute('''\n",
    "        INSERT OR REPLACE INTO canon_relation_init (id, output_entity_id, input_entity_id, relation_type)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "    ''', (relation_id, output_entity_id, input_entity_id, relation_type))\n",
    "\n",
    "# Commit changes and close the database connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data has been successfully copied and updated into the canon_relation_init table.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to SQLite database\n",
    "db_path = r\"your/custom/path/sgmkg.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create a new table canon_relation, including original fields and new fields: connectivity and frequency\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS canon_relation (\n",
    "        id TEXT PRIMARY KEY,\n",
    "        output_entity_id TEXT,\n",
    "        input_entity_id TEXT,\n",
    "        relation_type TEXT,\n",
    "        connectivity INTEGER,\n",
    "        frequency INTEGER\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Read data from the canon_relation_init table\n",
    "cursor.execute('SELECT id, output_entity_id, input_entity_id, relation_type FROM canon_relation_init')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Dictionary to track the frequency of the same output_entity_id and input_entity_id combinations\n",
    "relation_dict = {}\n",
    "\n",
    "# Iterate through rows and record the frequency of each (output_entity_id, input_entity_id) pair\n",
    "for row in rows:\n",
    "    relation_id, output_entity_id, input_entity_id, relation_type = row\n",
    "    key = (output_entity_id, input_entity_id)\n",
    "    \n",
    "    if key in relation_dict:\n",
    "        relation_dict[key]['frequency'] += 1\n",
    "    else:\n",
    "        relation_dict[key] = {\n",
    "            'relation_id': relation_id,\n",
    "            'output_entity_id': output_entity_id,\n",
    "            'input_entity_id': input_entity_id,\n",
    "            'relation_type': relation_type,\n",
    "            'frequency': 1,\n",
    "            'connectivity': 1\n",
    "        }\n",
    "\n",
    "# Insert the results into the new canon_relation table\n",
    "for key, value in relation_dict.items():\n",
    "    cursor.execute('''\n",
    "        INSERT OR REPLACE INTO canon_relation (\n",
    "            id, output_entity_id, input_entity_id, relation_type, connectivity, frequency\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?)\n",
    "    ''', (value['relation_id'], value['output_entity_id'], value['input_entity_id'], value['relation_type'], value['connectivity'], value['frequency']))\n",
    "\n",
    "# Commit changes and close the database connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"The canon_relation table has been successfully created and populated with data.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
