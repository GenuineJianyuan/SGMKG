{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to SQLite database\n",
    "db_path = r\"your/custom/path/sgmkg.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Execute query to retrieve new_id values starting with \"iodata\"\n",
    "cursor.execute('''\n",
    "    SELECT new_id FROM canon_entity\n",
    "    WHERE new_id LIKE 'iodata%'\n",
    "''')\n",
    "\n",
    "# Retrieve and convert the result to a set of new_id values\n",
    "iodata_ids = cursor.fetchall()\n",
    "iodata_ids = set([item[0] for item in iodata_ids])\n",
    "\n",
    "# Count the number of matching rows\n",
    "count = len(iodata_ids)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "print(f\"Number of matching rows: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sqlite3\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Load the .pth file\n",
    "pth_file_path = r\"your/custom/path/data_entity_preprocessing.pth\"\n",
    "data = torch.load(pth_file_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Connect to SQLite database and retrieve new_id values\n",
    "db_path = r\"your/custom/path/sgmkg.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''\n",
    "    SELECT new_id FROM canon_entity\n",
    "    WHERE new_id LIKE 'iodata%'\n",
    "''')\n",
    "\n",
    "iodata_ids = cursor.fetchall()\n",
    "iodata_ids = set([item[0] for item in iodata_ids])\n",
    "\n",
    "# Extract items matching the criteria\n",
    "new_embeddings = {k: v for k, v in data.items() if k in iodata_ids}\n",
    "\n",
    "# Define the function to calculate similarity\n",
    "def calculate_similarity(key, embeddings):\n",
    "    target_embedding = embeddings[key]\n",
    "    similarities = {}\n",
    "\n",
    "    for other_key, other_embedding in embeddings.items():\n",
    "        if key != other_key:\n",
    "            with torch.no_grad():\n",
    "                similarity = torch.nn.functional.cosine_similarity(target_embedding, other_embedding).item()\n",
    "            similarities[other_key] = similarity\n",
    "\n",
    "    # Get Top 3 similarities\n",
    "    top_3 = sorted(similarities.items(), key=lambda item: item[1], reverse=True)[:3]\n",
    "    print(f'Finish calculation for {key}')\n",
    "    return key, [{\"key\": other_key, \"similarity\": similarity} for other_key, similarity in top_3]\n",
    "\n",
    "# Use parallel computation to speed up similarity calculation\n",
    "results_dict = {}\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    results = list(executor.map(lambda k: calculate_similarity(k, new_embeddings), iodata_ids))\n",
    "    for key, top_3 in results:\n",
    "        results_dict[key] = top_3\n",
    "\n",
    "# Save results to a JSON file\n",
    "output_json_path = r\"your/custom/path/similarity_results.json\"\n",
    "with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_dict, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "print(f\"Similarity calculation complete. Results saved to: {output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Connect to SQLite database\n",
    "db_path = r\"your/custom/path/sgmkg.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Step 1: Copy canon_relation table to aug_relation table\n",
    "cursor.execute('DROP TABLE IF EXISTS aug_relation')  # Drop the old aug_relation table if it exists\n",
    "cursor.execute('''\n",
    "    CREATE TABLE aug_relation AS\n",
    "    SELECT * FROM canon_relation\n",
    "''')\n",
    "\n",
    "cursor.execute('DROP TABLE IF EXISTS aug_entity')  # Drop the old aug_entity table if it exists\n",
    "cursor.execute('''\n",
    "    CREATE TABLE aug_entity AS\n",
    "    SELECT * FROM canon_entity\n",
    "''')\n",
    "\n",
    "# Query to get new_id values starting with \"iodata\"\n",
    "cursor.execute('''\n",
    "    SELECT new_id FROM aug_entity\n",
    "    WHERE new_id LIKE 'iodata%'\n",
    "''')\n",
    "\n",
    "# Get the list of new_id values\n",
    "iodata_ids = cursor.fetchall()\n",
    "iodata_ids = set([item[0] for item in iodata_ids])  # Convert to a simple list\n",
    "\n",
    "# Read similarity_results.json file\n",
    "json_file_path = r\"your/custom/path/similarity_results.json\"\n",
    "with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "    similarity_data = json.load(file)\n",
    "\n",
    "# Iterate through each output_entity_id in the JSON file\n",
    "for output_entity_id, similar_items in similarity_data.items():\n",
    "    # Query aug_relation table for all 'transfer' relations with the current output_entity_id\n",
    "    cursor.execute('''\n",
    "        SELECT input_entity_id FROM aug_relation\n",
    "        WHERE relation_type = 'transfer'\n",
    "        AND output_entity_id = ?\n",
    "    ''', (output_entity_id,))\n",
    "    input_entity_ids = cursor.fetchall()\n",
    "    input_entity_ids = [item[0] for item in input_entity_ids]  # Extract input_entity_id list\n",
    "\n",
    "    # Randomly select 5 input_entity_ids if there are more than 5\n",
    "    if len(input_entity_ids) > 5:\n",
    "        input_entity_ids = random.sample(input_entity_ids, 5)\n",
    "\n",
    "    # Iterate through each similar item for the current output_entity_id\n",
    "    for item in similar_items:\n",
    "        similar_output_entity_id = item['key']\n",
    "        similarity = item['similarity']\n",
    "\n",
    "        # Skip the item if similarity is less than 0.68\n",
    "        if similarity < 0.68:\n",
    "            print(f\"Skipping {similar_output_entity_id} for {output_entity_id} due to low similarity: {similarity}\")\n",
    "            continue\n",
    "\n",
    "        # Iterate through all input_entity_ids\n",
    "        for input_entity_id in input_entity_ids:\n",
    "            # Check if the output_entity_id and input_entity_id combination already exists\n",
    "            cursor.execute('''\n",
    "                SELECT frequency FROM aug_relation\n",
    "                WHERE output_entity_id = ?\n",
    "                AND input_entity_id = ?\n",
    "                AND relation_type = 'transfer'\n",
    "            ''', (similar_output_entity_id, input_entity_id))\n",
    "            result = cursor.fetchone()\n",
    "\n",
    "            if not result:\n",
    "                # Insert a new row if the combination does not exist\n",
    "                cursor.execute('''\n",
    "                    INSERT INTO aug_relation (output_entity_id, input_entity_id, relation_type, connectivity, frequency)\n",
    "                    VALUES (?, ?, 'transfer', ?, 1)\n",
    "                ''', (similar_output_entity_id, input_entity_id, similarity))\n",
    "\n",
    "# Commit changes and close database connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Processing complete. All data has been updated in the aug_relation table.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
